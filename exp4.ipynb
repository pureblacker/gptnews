{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>﻿更博了，爆照了，帅的呀，就是越来越爱你！生快傻缺[爱你][爱你][爱你]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@张晓鹏jonathan 土耳其的事要认真对待[哈哈]，否则直接开除。@丁丁看世界 很是细心...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>姑娘都羡慕你呢…还有招财猫高兴……//@爱在蔓延-JC:[哈哈]小学徒一枚，等着明天见您呢/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>美~~~~~[爱你]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>梦想有多大，舞台就有多大![鼓掌]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119983</th>\n",
       "      <td>0</td>\n",
       "      <td>一公里不到，县医院那个天桥下右拐200米就到了！//@谢礼恒: 我靠。这个太霸道了！离224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119984</th>\n",
       "      <td>0</td>\n",
       "      <td>今天真冷啊，难道又要穿棉袄了[晕]？今年的春天真的是百变莫测啊[抓狂]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119985</th>\n",
       "      <td>0</td>\n",
       "      <td>最近几天就没停止过！！！[伤心]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119986</th>\n",
       "      <td>0</td>\n",
       "      <td>//@毒药女流氓:[怒] 很惨!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119987</th>\n",
       "      <td>0</td>\n",
       "      <td>呢??@杰?Kelena ？！[抓狂] ?搞乜鬼？？！！想知？入去GOtrip睇睇： htt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119988 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                             review\n",
       "0           1              ﻿更博了，爆照了，帅的呀，就是越来越爱你！生快傻缺[爱你][爱你][爱你]\n",
       "1           1  @张晓鹏jonathan 土耳其的事要认真对待[哈哈]，否则直接开除。@丁丁看世界 很是细心...\n",
       "2           1  姑娘都羡慕你呢…还有招财猫高兴……//@爱在蔓延-JC:[哈哈]小学徒一枚，等着明天见您呢/...\n",
       "3           1                                         美~~~~~[爱你]\n",
       "4           1                                  梦想有多大，舞台就有多大![鼓掌]\n",
       "...       ...                                                ...\n",
       "119983      0  一公里不到，县医院那个天桥下右拐200米就到了！//@谢礼恒: 我靠。这个太霸道了！离224...\n",
       "119984      0                今天真冷啊，难道又要穿棉袄了[晕]？今年的春天真的是百变莫测啊[抓狂]\n",
       "119985      0                                   最近几天就没停止过！！！[伤心]\n",
       "119986      0                                   //@毒药女流氓:[怒] 很惨!\n",
       "119987      0  呢??@杰?Kelena ？！[抓狂] ?搞乜鬼？？！！想知？入去GOtrip睇睇： htt...\n",
       "\n",
       "[119988 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('./weibo_senti_100k.csv')\n",
    "data=data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\YaliZhu\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.784 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>data_cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>﻿更博了，爆照了，帅的呀，就是越来越爱你！生快傻缺[爱你][爱你][爱你]</td>\n",
       "      <td>[﻿, 更博, 了, ，, 爆照, 了, ，, 帅, 的, 呀, ，, 就是, 越来越, 爱...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@张晓鹏jonathan 土耳其的事要认真对待[哈哈]，否则直接开除。@丁丁看世界 很是细心...</td>\n",
       "      <td>[@, 张晓鹏, jonathan,  , 土耳其, 的, 事要, 认真对待, [, 哈哈,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>姑娘都羡慕你呢…还有招财猫高兴……//@爱在蔓延-JC:[哈哈]小学徒一枚，等着明天见您呢/...</td>\n",
       "      <td>[姑娘, 都, 羡慕, 你, 呢, …, 还有, 招财猫, 高兴, …, …, /, /, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>美~~~~~[爱你]</td>\n",
       "      <td>[美, ~, ~, ~, ~, ~, [, 爱, 你, ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>梦想有多大，舞台就有多大![鼓掌]</td>\n",
       "      <td>[梦想, 有, 多, 大, ，, 舞台, 就, 有, 多, 大, !, [, 鼓掌, ]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             review  \\\n",
       "0      1              ﻿更博了，爆照了，帅的呀，就是越来越爱你！生快傻缺[爱你][爱你][爱你]   \n",
       "1      1  @张晓鹏jonathan 土耳其的事要认真对待[哈哈]，否则直接开除。@丁丁看世界 很是细心...   \n",
       "2      1  姑娘都羡慕你呢…还有招财猫高兴……//@爱在蔓延-JC:[哈哈]小学徒一枚，等着明天见您呢/...   \n",
       "3      1                                         美~~~~~[爱你]   \n",
       "4      1                                  梦想有多大，舞台就有多大![鼓掌]   \n",
       "\n",
       "                                            data_cut  \n",
       "0  [﻿, 更博, 了, ，, 爆照, 了, ，, 帅, 的, 呀, ，, 就是, 越来越, 爱...  \n",
       "1  [@, 张晓鹏, jonathan,  , 土耳其, 的, 事要, 认真对待, [, 哈哈,...  \n",
       "2  [姑娘, 都, 羡慕, 你, 呢, …, 还有, 招财猫, 高兴, …, …, /, /, ...  \n",
       "3                     [美, ~, ~, ~, ~, ~, [, 爱, 你, ]]  \n",
       "4      [梦想, 有, 多, 大, ，, 舞台, 就, 有, 多, 大, !, [, 鼓掌, ]]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "data['data_cut'] = data['review'].apply(lambda x: list(jieba.cut(x))) #内嵌自定义函数来分词\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>data_cut</th>\n",
       "      <th>data_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>﻿更博了，爆照了，帅的呀，就是越来越爱你！生快傻缺[爱你][爱你][爱你]</td>\n",
       "      <td>[﻿, 更博, 了, ，, 爆照, 了, ，, 帅, 的, 呀, ，, 就是, 越来越, 爱...</td>\n",
       "      <td>[﻿, 更博, 爆照, 帅, 越来越, 爱, 生快, 傻, 缺, 爱, 爱, 爱]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@张晓鹏jonathan 土耳其的事要认真对待[哈哈]，否则直接开除。@丁丁看世界 很是细心...</td>\n",
       "      <td>[@, 张晓鹏, jonathan,  , 土耳其, 的, 事要, 认真对待, [, 哈哈,...</td>\n",
       "      <td>[张晓鹏, jonathan,  , 土耳其, 事要, 认真对待, 开除, 丁丁, 世界, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>姑娘都羡慕你呢…还有招财猫高兴……//@爱在蔓延-JC:[哈哈]小学徒一枚，等着明天见您呢/...</td>\n",
       "      <td>[姑娘, 都, 羡慕, 你, 呢, …, 还有, 招财猫, 高兴, …, …, /, /, ...</td>\n",
       "      <td>[姑娘, 羡慕, 招财猫, 爱, 蔓延, JC, 学徒, 一枚, 明天, 李欣芸, Shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>美~~~~~[爱你]</td>\n",
       "      <td>[美, ~, ~, ~, ~, ~, [, 爱, 你, ]]</td>\n",
       "      <td>[美, 爱]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>梦想有多大，舞台就有多大![鼓掌]</td>\n",
       "      <td>[梦想, 有, 多, 大, ，, 舞台, 就, 有, 多, 大, !, [, 鼓掌, ]]</td>\n",
       "      <td>[梦想, 舞台, 鼓掌]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             review  \\\n",
       "0      1              ﻿更博了，爆照了，帅的呀，就是越来越爱你！生快傻缺[爱你][爱你][爱你]   \n",
       "1      1  @张晓鹏jonathan 土耳其的事要认真对待[哈哈]，否则直接开除。@丁丁看世界 很是细心...   \n",
       "2      1  姑娘都羡慕你呢…还有招财猫高兴……//@爱在蔓延-JC:[哈哈]小学徒一枚，等着明天见您呢/...   \n",
       "3      1                                         美~~~~~[爱你]   \n",
       "4      1                                  梦想有多大，舞台就有多大![鼓掌]   \n",
       "\n",
       "                                            data_cut  \\\n",
       "0  [﻿, 更博, 了, ，, 爆照, 了, ，, 帅, 的, 呀, ，, 就是, 越来越, 爱...   \n",
       "1  [@, 张晓鹏, jonathan,  , 土耳其, 的, 事要, 认真对待, [, 哈哈,...   \n",
       "2  [姑娘, 都, 羡慕, 你, 呢, …, 还有, 招财猫, 高兴, …, …, /, /, ...   \n",
       "3                     [美, ~, ~, ~, ~, ~, [, 爱, 你, ]]   \n",
       "4      [梦想, 有, 多, 大, ，, 舞台, 就, 有, 多, 大, !, [, 鼓掌, ]]   \n",
       "\n",
       "                                          data_after  \n",
       "0          [﻿, 更博, 爆照, 帅, 越来越, 爱, 生快, 傻, 缺, 爱, 爱, 爱]  \n",
       "1  [张晓鹏, jonathan,  , 土耳其, 事要, 认真对待, 开除, 丁丁, 世界, ...  \n",
       "2  [姑娘, 羡慕, 招财猫, 爱, 蔓延, JC, 学徒, 一枚, 明天, 李欣芸, Shar...  \n",
       "3                                             [美, 爱]  \n",
       "4                                       [梦想, 舞台, 鼓掌]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去停用词\n",
    "# 读取停用词\n",
    "with open('stopword.txt','r',encoding = 'utf-8') as f: #读取停用词txt 文档\n",
    "    stop = f.readlines()\n",
    "# 对停用词处理\n",
    "import re\n",
    "stop = [re.sub(' |\\n|\\ufeff','',r) for r in stop] #替换停用词表的空格等\n",
    "# 去除停用词\n",
    "#把分词之后的文本根据停用词表去掉停用词\n",
    "data['data_after'] = [[i for i in s if i not in stop] for s in data['data_cut']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>data_cut</th>\n",
       "      <th>data_after</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>﻿更博了，爆照了，帅的呀，就是越来越爱你！生快傻缺[爱你][爱你][爱你]</td>\n",
       "      <td>[﻿, 更博, 了, ，, 爆照, 了, ，, 帅, 的, 呀, ，, 就是, 越来越, 爱...</td>\n",
       "      <td>[﻿, 更博, 爆照, 帅, 越来越, 爱, 生快, 傻, 缺, 爱, 爱, 爱]</td>\n",
       "      <td>[83982, 53281, 56556, 481, 312, 4, 2270, 451, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@张晓鹏jonathan 土耳其的事要认真对待[哈哈]，否则直接开除。@丁丁看世界 很是细心...</td>\n",
       "      <td>[@, 张晓鹏, jonathan,  , 土耳其, 的, 事要, 认真对待, [, 哈哈,...</td>\n",
       "      <td>[张晓鹏, jonathan,  , 土耳其, 事要, 认真对待, 开除, 丁丁, 世界, ...</td>\n",
       "      <td>[8590, 9062, 1, 4948, 29179, 49557, 13038, 217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>姑娘都羡慕你呢…还有招财猫高兴……//@爱在蔓延-JC:[哈哈]小学徒一枚，等着明天见您呢/...</td>\n",
       "      <td>[姑娘, 都, 羡慕, 你, 呢, …, 还有, 招财猫, 高兴, …, …, /, /, ...</td>\n",
       "      <td>[姑娘, 羡慕, 招财猫, 爱, 蔓延, JC, 学徒, 一枚, 明天, 李欣芸, Shar...</td>\n",
       "      <td>[275, 484, 19532, 4, 3078, 6659, 9211, 1979, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>美~~~~~[爱你]</td>\n",
       "      <td>[美, ~, ~, ~, ~, ~, [, 爱, 你, ]]</td>\n",
       "      <td>[美, 爱]</td>\n",
       "      <td>[126, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>梦想有多大，舞台就有多大![鼓掌]</td>\n",
       "      <td>[梦想, 有, 多, 大, ，, 舞台, 就, 有, 多, 大, !, [, 鼓掌, ]]</td>\n",
       "      <td>[梦想, 舞台, 鼓掌]</td>\n",
       "      <td>[326, 1466, 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             review  \\\n",
       "0      1              ﻿更博了，爆照了，帅的呀，就是越来越爱你！生快傻缺[爱你][爱你][爱你]   \n",
       "1      1  @张晓鹏jonathan 土耳其的事要认真对待[哈哈]，否则直接开除。@丁丁看世界 很是细心...   \n",
       "2      1  姑娘都羡慕你呢…还有招财猫高兴……//@爱在蔓延-JC:[哈哈]小学徒一枚，等着明天见您呢/...   \n",
       "3      1                                         美~~~~~[爱你]   \n",
       "4      1                                  梦想有多大，舞台就有多大![鼓掌]   \n",
       "\n",
       "                                            data_cut  \\\n",
       "0  [﻿, 更博, 了, ，, 爆照, 了, ，, 帅, 的, 呀, ，, 就是, 越来越, 爱...   \n",
       "1  [@, 张晓鹏, jonathan,  , 土耳其, 的, 事要, 认真对待, [, 哈哈,...   \n",
       "2  [姑娘, 都, 羡慕, 你, 呢, …, 还有, 招财猫, 高兴, …, …, /, /, ...   \n",
       "3                     [美, ~, ~, ~, ~, ~, [, 爱, 你, ]]   \n",
       "4      [梦想, 有, 多, 大, ，, 舞台, 就, 有, 多, 大, !, [, 鼓掌, ]]   \n",
       "\n",
       "                                          data_after  \\\n",
       "0          [﻿, 更博, 爆照, 帅, 越来越, 爱, 生快, 傻, 缺, 爱, 爱, 爱]   \n",
       "1  [张晓鹏, jonathan,  , 土耳其, 事要, 认真对待, 开除, 丁丁, 世界, ...   \n",
       "2  [姑娘, 羡慕, 招财猫, 爱, 蔓延, JC, 学徒, 一枚, 明天, 李欣芸, Shar...   \n",
       "3                                             [美, 爱]   \n",
       "4                                       [梦想, 舞台, 鼓掌]   \n",
       "\n",
       "                                                 vec  \n",
       "0  [83982, 53281, 56556, 481, 312, 4, 2270, 451, ...  \n",
       "1  [8590, 9062, 1, 4948, 29179, 49557, 13038, 217...  \n",
       "2  [275, 484, 19532, 4, 3078, 6659, 9211, 1979, 7...  \n",
       "3                                           [126, 4]  \n",
       "4                                     [326, 1466, 6]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建词向量矩阵\n",
    "w = []\n",
    "for i in data['data_after']:\n",
    "    w.extend(i) #将所有词语整合在一起\n",
    "num_data = pd.DataFrame(pd.Series(w).value_counts()) # 计算出所有单词的个数\n",
    "num_data['id'] = list(range(1,len(num_data)+1)) #把这些数据增加序号\n",
    "# 转化成数字\n",
    "a = lambda x:list(num_data['id'][x]) #以序号为序定义实现函数\n",
    "data['vec'] = data['data_after'].apply(a) #apply（）方法实现\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建词云\n",
    "#加载词云库\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "# ## 词频统计\n",
    "# 重组词组\n",
    "num_words = [''.join(i) for i in data['data_after']] #把所有词提取出来\n",
    "num_words = ''.join(num_words) # 把所有词拼接成一个字符串\n",
    "num_words= re.sub(' ','',num_words) #去除空格\n",
    "# 计算全部词频\n",
    "num = pd.Series(jieba.lcut(num_words)).value_counts()\n",
    "# 用wordcloud 画图\n",
    "wc_pic =WordCloud(background_color='white',font_path=r'C:\\Windows\\Fonts\\simhei.ttf').fit_words(num)\n",
    "plt.figure(figsize=(15,15)) #图片大小定义\n",
    "plt.imshow(wc_pic)#输出图片\n",
    "plt.axis('off')#不显示坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 数据集划分\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "# maxlen = 100 #句子长度\n",
    "data_vec = list(data['vec'].values)\n",
    "data_label = torch.tensor(list(data['label'].values),dtype=torch.float32)\n",
    "vec_data = pad_sequence([torch.from_numpy(np.array(x)) for x in data_vec],batch_first=True)#把文本数据都统一长度\n",
    "x_train,x_test,y_train,y_test = train_test_split(vec_data,data_label,test_size = 0.2,random_state= 124) #分割训练集--2-8 原则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(C=1, kernel = 'linear',max_iter=2000) # 用线性分类器\n",
    "clf.fit(x,y) # #模型训练\n",
    "# 调用报告\n",
    "from sklearn.metrics import classification_report\n",
    "test_pre = clf.predict(xt) # 模型预测\n",
    "report = classification_report(yt,test_pre) #预测结果\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Embedding,LSTM,Linear,Sigmoid,Sequential,Flatten,Module\n",
    "import torch.nn.functional as F\n",
    "class Models(Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(Models, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm =LSTM(input_size=embedding_dim,hidden_size=hidden_dim,num_layers=1,batch_first=True)\n",
    "        self.linear2 = Linear(hidden_dim, tagset_size)\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # 一开始并没有隐藏状态所以我们要先初始化一个\n",
    "        # 关于维度为什么这么设计请参考Pytoch相关文档\n",
    "        # 各个维度的含义是 (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(1, 1, self.hidden_dim),\n",
    "                torch.zeros(1, 1, self.hidden_dim))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        out = self.embeddings(sentence)\n",
    "        # out = self.linear1(out)   #1,123seq_len,128hidden\n",
    "        lstm_out, self.hidden = self.lstm(out, self.hidden)\n",
    "        tag_space = self.linear2(lstm_out[...,-1,:])\n",
    "        tag_scores = F.sigmoid(tag_space)\n",
    "        return tag_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Models(\n",
       "  (embeddings): Embedding(201995, 256)\n",
       "  (lstm): LSTM(256, 128, batch_first=True)\n",
       "  (linear2): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Models(embedding_dim=256, hidden_dim=128, vocab_size=201995, tagset_size=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=model.to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "loss=torch.nn.BCELoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 123])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved variables after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved variables after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\YaliZhu\\Desktop\\ruanjianbei\\gptnews\\exp4.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YaliZhu/Desktop/ruanjianbei/gptnews/exp4.ipynb#ch0000018?line=12'>13</a>\u001b[0m     y_pred\u001b[39m=\u001b[39mmodel(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YaliZhu/Desktop/ruanjianbei/gptnews/exp4.ipynb#ch0000018?line=13'>14</a>\u001b[0m     loss_\u001b[39m=\u001b[39mloss(y_pred,y)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/YaliZhu/Desktop/ruanjianbei/gptnews/exp4.ipynb#ch0000018?line=14'>15</a>\u001b[0m     loss_\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YaliZhu/Desktop/ruanjianbei/gptnews/exp4.ipynb#ch0000018?line=15'>16</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YaliZhu/Desktop/ruanjianbei/gptnews/exp4.ipynb#ch0000018?line=17'>18</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py:255\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/torch/lib/site-packages/torch/_tensor.py?line=245'>246</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/torch/lib/site-packages/torch/_tensor.py?line=246'>247</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/torch/lib/site-packages/torch/_tensor.py?line=247'>248</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/torch/lib/site-packages/torch/_tensor.py?line=248'>249</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/torch/lib/site-packages/torch/_tensor.py?line=252'>253</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/torch/lib/site-packages/torch/_tensor.py?line=253'>254</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/torch/lib/site-packages/torch/_tensor.py?line=254'>255</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py:147\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/torch/lib/site-packages/torch/autograd/__init__.py?line=143'>144</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/torch/lib/site-packages/torch/autograd/__init__.py?line=144'>145</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/torch/lib/site-packages/torch/autograd/__init__.py?line=146'>147</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/torch/lib/site-packages/torch/autograd/__init__.py?line=147'>148</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/torch/lib/site-packages/torch/autograd/__init__.py?line=148'>149</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved variables after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved variables after calling backward."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# 模型训练\n",
    "epochs=10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for x,y in tqdm(zip(x_train,y_train)):\n",
    "        optimizer.zero_grad()\n",
    "        x=x.reshape(1,x.shape[0])   #batch size=1\n",
    "        print(x.shape)\n",
    "        y=y.reshape(1,1)\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        y_pred=model(x)\n",
    "        loss_=loss(y_pred,y)\n",
    "        loss_.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred=model(x_test)\n",
    "        y_pred=y_pred.squeeze()\n",
    "        y_pred=y_pred>0.5\n",
    "        y_pred=y_pred.cpu().numpy()\n",
    "        y_test=y_test.cpu().numpy()\n",
    "        print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型验证\n",
    "loss,accuracy=model.(x_test,y_test,batch_size=12) # 测试集评估\n",
    "print('Test loss:',loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7fb8039a8f54b6eaa53411e1600db4762c5d3778c5768c8cb602a31c798a2c38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
